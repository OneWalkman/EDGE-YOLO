# Ultralytics ğŸš€ AGPL-3.0 License - https://ultralytics.com/license
"""Convolution modules."""

import math
import pywt

import numpy as np
import torch
import torch.nn as nn
import torch.nn.functional as F

__all__ = (
    "Conv",
    "Conv2",
    "LightConv",
    "DWConv",
    "DWConvTranspose2d",
    "ConvTranspose",
    "Focus",
    "GhostConv",
    "ChannelAttention",
    "SpatialAttention",
    "CBAM",
    "Concat",
    "RepConv",
    "Index",
    "DSConv",
    "WTConv2d",
)


def autopad(k, p=None, d=1):  # kernel, padding, dilation
    """Pad to 'same' shape outputs."""
    if d > 1:
        k = d * (k - 1) + 1 if isinstance(k, int) else [d * (x - 1) + 1 for x in k]  # actual kernel-size
    if p is None:
        p = k // 2 if isinstance(k, int) else [x // 2 for x in k]  # auto-pad
    return p


class Conv(nn.Module):
    """Standard convolution with args(ch_in, ch_out, kernel, stride, padding, groups, dilation, activation)."""

    default_act = nn.SiLU()  # default activation

    def __init__(self, c1, c2, k=1, s=1, p=None, g=1, d=1, act=True):
        """Initialize Conv layer with given arguments including activation."""
        super().__init__()
        self.conv = nn.Conv2d(c1, c2, k, s, autopad(k, p, d), groups=g, dilation=d, bias=False)
        self.bn = nn.BatchNorm2d(c2)
        self.act = self.default_act if act is True else act if isinstance(act, nn.Module) else nn.Identity()

    def forward(self, x):
        """Apply convolution, batch normalization and activation to input tensor."""
        return self.act(self.bn(self.conv(x)))

    def forward_fuse(self, x):
        """Apply convolution and activation without batch normalization."""
        return self.act(self.conv(x))


class Conv2(Conv):
    """Simplified RepConv module with Conv fusing."""

    def __init__(self, c1, c2, k=3, s=1, p=None, g=1, d=1, act=True):
        """Initialize Conv layer with given arguments including activation."""
        super().__init__(c1, c2, k, s, p, g=g, d=d, act=act)
        self.cv2 = nn.Conv2d(c1, c2, 1, s, autopad(1, p, d), groups=g, dilation=d, bias=False)  # add 1x1 conv

    def forward(self, x):
        """Apply convolution, batch normalization and activation to input tensor."""
        return self.act(self.bn(self.conv(x) + self.cv2(x)))

    def forward_fuse(self, x):
        """Apply fused convolution, batch normalization and activation to input tensor."""
        return self.act(self.bn(self.conv(x)))

    def fuse_convs(self):
        """Fuse parallel convolutions."""
        w = torch.zeros_like(self.conv.weight.data)
        i = [x // 2 for x in w.shape[2:]]
        w[:, :, i[0] : i[0] + 1, i[1] : i[1] + 1] = self.cv2.weight.data.clone()
        self.conv.weight.data += w
        self.__delattr__("cv2")
        self.forward = self.forward_fuse

class DSConv(nn.Module):
    """The Basic Depthwise Separable Convolution."""
    def __init__(self, c_in, c_out, k=3, s=1, p=None, d=1, bias=False):
        super().__init__()
        if p is None:
            p = (d * (k - 1)) // 2
        self.dw = nn.Conv2d(
            c_in, c_in, kernel_size=k, stride=s,
            padding=p, dilation=d, groups=c_in, bias=bias
        )
        self.pw = nn.Conv2d(c_in, c_out, 1, 1, 0, bias=bias)
        self.bn = nn.BatchNorm2d(c_out)
        self.act = nn.SiLU()

    def forward(self, x):
        x = self.dw(x)
        x = self.pw(x)
        return self.act(self.bn(x))

class LightConv(nn.Module):
    """
    Light convolution with args(ch_in, ch_out, kernel).

    https://github.com/PaddlePaddle/PaddleDetection/blob/develop/ppdet/modeling/backbones/hgnet_v2.py
    """

    def __init__(self, c1, c2, k=1, act=nn.ReLU()):
        """Initialize Conv layer with given arguments including activation."""
        super().__init__()
        self.conv1 = Conv(c1, c2, 1, act=False)
        self.conv2 = DWConv(c2, c2, k, act=act)

    def forward(self, x):
        """Apply 2 convolutions to input tensor."""
        return self.conv2(self.conv1(x))


class DWConv(Conv):
    """Depth-wise convolution."""

    def __init__(self, c1, c2, k=1, s=1, d=1, act=True):  # ch_in, ch_out, kernel, stride, dilation, activation
        """Initialize Depth-wise convolution with given parameters."""
        super().__init__(c1, c2, k, s, g=math.gcd(c1, c2), d=d, act=act)


class DWConvTranspose2d(nn.ConvTranspose2d):
    """Depth-wise transpose convolution."""

    def __init__(self, c1, c2, k=1, s=1, p1=0, p2=0):  # ch_in, ch_out, kernel, stride, padding, padding_out
        """Initialize DWConvTranspose2d class with given parameters."""
        super().__init__(c1, c2, k, s, p1, p2, groups=math.gcd(c1, c2))


class ConvTranspose(nn.Module):
    """Convolution transpose 2d layer."""

    default_act = nn.SiLU()  # default activation

    def __init__(self, c1, c2, k=2, s=2, p=0, bn=True, act=True):
        """Initialize ConvTranspose2d layer with batch normalization and activation function."""
        super().__init__()
        self.conv_transpose = nn.ConvTranspose2d(c1, c2, k, s, p, bias=not bn)
        self.bn = nn.BatchNorm2d(c2) if bn else nn.Identity()
        self.act = self.default_act if act is True else act if isinstance(act, nn.Module) else nn.Identity()

    def forward(self, x):
        """Applies transposed convolutions, batch normalization and activation to input."""
        return self.act(self.bn(self.conv_transpose(x)))

    def forward_fuse(self, x):
        """Applies activation and convolution transpose operation to input."""
        return self.act(self.conv_transpose(x))


class Focus(nn.Module):
    """Focus wh information into c-space."""

    def __init__(self, c1, c2, k=1, s=1, p=None, g=1, act=True):
        """Initializes Focus object with user defined channel, convolution, padding, group and activation values."""
        super().__init__()
        self.conv = Conv(c1 * 4, c2, k, s, p, g, act=act)
        # self.contract = Contract(gain=2)

    def forward(self, x):
        """
        Applies convolution to concatenated tensor and returns the output.

        Input shape is (b,c,w,h) and output shape is (b,4c,w/2,h/2).
        """
        return self.conv(torch.cat((x[..., ::2, ::2], x[..., 1::2, ::2], x[..., ::2, 1::2], x[..., 1::2, 1::2]), 1))
        # return self.conv(self.contract(x))


class GhostConv(nn.Module):
    """Ghost Convolution https://github.com/huawei-noah/ghostnet."""

    def __init__(self, c1, c2, k=1, s=1, g=1, act=True):
        """Initializes Ghost Convolution module with primary and cheap operations for efficient feature learning."""
        super().__init__()
        c_ = c2 // 2  # hidden channels
        self.cv1 = Conv(c1, c_, k, s, None, g, act=act)
        self.cv2 = Conv(c_, c_, 5, 1, None, c_, act=act)

    def forward(self, x):
        """Forward propagation through a Ghost Bottleneck layer with skip connection."""
        y = self.cv1(x)
        return torch.cat((y, self.cv2(y)), 1)


class RepConv(nn.Module):
    """
    RepConv is a basic rep-style block, including training and deploy status.

    This module is used in RT-DETR.
    Based on https://github.com/DingXiaoH/RepVGG/blob/main/repvgg.py
    """

    default_act = nn.SiLU()  # default activation

    def __init__(self, c1, c2, k=3, s=1, p=1, g=1, d=1, act=True, bn=False, deploy=False):
        """Initializes Light Convolution layer with inputs, outputs & optional activation function."""
        super().__init__()
        assert k == 3 and p == 1
        self.g = g
        self.c1 = c1
        self.c2 = c2
        self.act = self.default_act if act is True else act if isinstance(act, nn.Module) else nn.Identity()

        self.bn = nn.BatchNorm2d(num_features=c1) if bn and c2 == c1 and s == 1 else None
        self.conv1 = Conv(c1, c2, k, s, p=p, g=g, act=False)
        self.conv2 = Conv(c1, c2, 1, s, p=(p - k // 2), g=g, act=False)

    def forward_fuse(self, x):
        """Forward process."""
        return self.act(self.conv(x))

    def forward(self, x):
        """Forward process."""
        id_out = 0 if self.bn is None else self.bn(x)
        return self.act(self.conv1(x) + self.conv2(x) + id_out)

    def get_equivalent_kernel_bias(self):
        """Returns equivalent kernel and bias by adding 3x3 kernel, 1x1 kernel and identity kernel with their biases."""
        kernel3x3, bias3x3 = self._fuse_bn_tensor(self.conv1)
        kernel1x1, bias1x1 = self._fuse_bn_tensor(self.conv2)
        kernelid, biasid = self._fuse_bn_tensor(self.bn)
        return kernel3x3 + self._pad_1x1_to_3x3_tensor(kernel1x1) + kernelid, bias3x3 + bias1x1 + biasid

    @staticmethod
    def _pad_1x1_to_3x3_tensor(kernel1x1):
        """Pads a 1x1 tensor to a 3x3 tensor."""
        if kernel1x1 is None:
            return 0
        else:
            return torch.nn.functional.pad(kernel1x1, [1, 1, 1, 1])

    def _fuse_bn_tensor(self, branch):
        """Generates appropriate kernels and biases for convolution by fusing branches of the neural network."""
        if branch is None:
            return 0, 0
        if isinstance(branch, Conv):
            kernel = branch.conv.weight
            running_mean = branch.bn.running_mean
            running_var = branch.bn.running_var
            gamma = branch.bn.weight
            beta = branch.bn.bias
            eps = branch.bn.eps
        elif isinstance(branch, nn.BatchNorm2d):
            if not hasattr(self, "id_tensor"):
                input_dim = self.c1 // self.g
                kernel_value = np.zeros((self.c1, input_dim, 3, 3), dtype=np.float32)
                for i in range(self.c1):
                    kernel_value[i, i % input_dim, 1, 1] = 1
                self.id_tensor = torch.from_numpy(kernel_value).to(branch.weight.device)
            kernel = self.id_tensor
            running_mean = branch.running_mean
            running_var = branch.running_var
            gamma = branch.weight
            beta = branch.bias
            eps = branch.eps
        std = (running_var + eps).sqrt()
        t = (gamma / std).reshape(-1, 1, 1, 1)
        return kernel * t, beta - running_mean * gamma / std

    def fuse_convs(self):
        """Combines two convolution layers into a single layer and removes unused attributes from the class."""
        if hasattr(self, "conv"):
            return
        kernel, bias = self.get_equivalent_kernel_bias()
        self.conv = nn.Conv2d(
            in_channels=self.conv1.conv.in_channels,
            out_channels=self.conv1.conv.out_channels,
            kernel_size=self.conv1.conv.kernel_size,
            stride=self.conv1.conv.stride,
            padding=self.conv1.conv.padding,
            dilation=self.conv1.conv.dilation,
            groups=self.conv1.conv.groups,
            bias=True,
        ).requires_grad_(False)
        self.conv.weight.data = kernel
        self.conv.bias.data = bias
        for para in self.parameters():
            para.detach_()
        self.__delattr__("conv1")
        self.__delattr__("conv2")
        if hasattr(self, "nm"):
            self.__delattr__("nm")
        if hasattr(self, "bn"):
            self.__delattr__("bn")
        if hasattr(self, "id_tensor"):
            self.__delattr__("id_tensor")


class ChannelAttention(nn.Module):
    """Channel-attention module https://github.com/open-mmlab/mmdetection/tree/v3.0.0rc1/configs/rtmdet."""

    def __init__(self, channels: int) -> None:
        """Initializes the class and sets the basic configurations and instance variables required."""
        super().__init__()
        self.pool = nn.AdaptiveAvgPool2d(1)
        self.fc = nn.Conv2d(channels, channels, 1, 1, 0, bias=True)
        self.act = nn.Sigmoid()

    def forward(self, x: torch.Tensor) -> torch.Tensor:
        """Applies forward pass using activation on convolutions of the input, optionally using batch normalization."""
        return x * self.act(self.fc(self.pool(x)))


class SpatialAttention(nn.Module):
    """Spatial-attention module."""

    def __init__(self, kernel_size=7):
        """Initialize Spatial-attention module with kernel size argument."""
        super().__init__()
        assert kernel_size in {3, 7}, "kernel size must be 3 or 7"
        padding = 3 if kernel_size == 7 else 1
        self.cv1 = nn.Conv2d(2, 1, kernel_size, padding=padding, bias=False)
        self.act = nn.Sigmoid()

    def forward(self, x):
        """Apply channel and spatial attention on input for feature recalibration."""
        return x * self.act(self.cv1(torch.cat([torch.mean(x, 1, keepdim=True), torch.max(x, 1, keepdim=True)[0]], 1)))


class CBAM(nn.Module):
    """Convolutional Block Attention Module."""

    def __init__(self, c1, kernel_size=7):
        """Initialize CBAM with given input channel (c1) and kernel size."""
        super().__init__()
        self.channel_attention = ChannelAttention(c1)
        self.spatial_attention = SpatialAttention(kernel_size)

    def forward(self, x):
        """Applies the forward pass through C1 module."""
        return self.spatial_attention(self.channel_attention(x))


class Concat(nn.Module):
    """Concatenate a list of tensors along dimension."""

    def __init__(self, dimension=1):
        """Concatenates a list of tensors along a specified dimension."""
        super().__init__()
        self.d = dimension

    def forward(self, x):
        """Forward pass for the YOLOv8 mask Proto module."""
        return torch.cat(x, self.d)

class ASFFLite(nn.Module):
    """è½»é‡ç‰ˆ ASFFï¼šæ¯ä¸ªåˆ†æ”¯å‡º1é€šé“æ³¨æ„åŠ›å›¾ï¼ŒSoftmax åé€åƒç´ åŠ æƒç›¸åŠ ã€‚å¯æ›¿æ¢-Contact"""
    def __init__(self, in_ch, out_ch, n_inputs):
        super().__init__()
        self.to_score = nn.ModuleList([nn.Conv2d(in_ch, 1, 1) for _ in range(n_inputs)])
        self.proj = nn.Sequential(nn.Conv2d(in_ch, out_ch, 1, bias=False),
                                  nn.BatchNorm2d(out_ch), nn.SiLU(True))

    def forward(self, xs):  # xs: List[N,C,H,W], å·²å¯¹é½é€šé“/å°ºå¯¸
        scores = [s(x) for s, x in zip(self.to_score, xs)]           # [N,1,H,W] * n
        attn = torch.softmax(torch.cat(scores, dim=1), dim=1)        # [N,n,H,W]
        y = sum(attn[:, i:i+1] * xi for i, xi in enumerate(xs))      # é€åƒç´ èåˆ
        return self.proj(y)

class WeightedAdd(nn.Module):
    """BiFPNå¼å¿«é€Ÿå½’ä¸€åŒ–åŠ æƒèåˆï¼ˆæ ‡é‡æƒé‡ã€å¯è®­ç»ƒã€éè´Ÿï¼‰ã€‚å¯æ›¿æ¢-Contact"""
    def __init__(self, n_inputs, eps=1e-4):
        super().__init__()
        self.w = nn.Parameter(torch.ones(n_inputs, dtype=torch.float32))
        self.eps = eps
        # å¯é€‰ï¼šåç½®1x1æŠŠé€šé“å¯¹é½åˆ°æœŸæœ›å€¼
        self.post = None

    def set_post(self, in_ch, out_ch):
        self.post = nn.Sequential(nn.Conv2d(in_ch, out_ch, 1, bias=False),
                                  nn.BatchNorm2d(out_ch), nn.SiLU(True))

    def forward(self, xs):
        # xs: List[N,C,H,W]ï¼Œéœ€åŒå½¢çŠ¶ï¼ˆæˆ–å…ˆå„è‡ªç”¨1x1å¯¹é½ï¼‰
        w = torch.relu(self.w)
        w = w / (w.sum() + self.eps)           # fast normalized fusion
        y = sum(wi * xi for wi, xi in zip(w, xs))
        return self.post(y) if self.post else y


class Index(nn.Module):
    """Returns a particular index of the input."""

    def __init__(self, c1, c2, index=0):
        """Returns a particular index of the input."""
        super().__init__()
        self.index = index

    def forward(self, x):
        """
        Forward pass.

        Expects a list of tensors as input.
        """
        return x[self.index]

def create_2d_wavelet_filter(wave, in_size, out_size, type=torch.float):
    w = pywt.Wavelet(wave)
    dec_hi = torch.tensor(w.dec_hi[::-1], dtype=type)
    dec_lo = torch.tensor(w.dec_lo[::-1], dtype=type)
    dec_filters = torch.stack([dec_lo.unsqueeze(0) * dec_lo.unsqueeze(1),
                               dec_lo.unsqueeze(0) * dec_hi.unsqueeze(1),
                               dec_hi.unsqueeze(0) * dec_lo.unsqueeze(1),
                               dec_hi.unsqueeze(0) * dec_hi.unsqueeze(1)], dim=0)

    dec_filters = dec_filters[:, None].repeat(in_size, 1, 1, 1)

    rec_hi = torch.tensor(w.rec_hi, dtype=type)
    rec_lo = torch.tensor(w.rec_lo, dtype=type)
    rec_filters = torch.stack([rec_lo.unsqueeze(0) * rec_lo.unsqueeze(1),
                               rec_lo.unsqueeze(0) * rec_hi.unsqueeze(1),
                               rec_hi.unsqueeze(0) * rec_lo.unsqueeze(1),
                               rec_hi.unsqueeze(0) * rec_hi.unsqueeze(1)], dim=0)

    rec_filters = rec_filters[:, None].repeat(out_size, 1, 1, 1)

    return dec_filters, rec_filters

def wavelet_2d_transform(x, filters):
    b, c, h, w = x.shape
    pad = (filters.shape[2] // 2 - 1, filters.shape[3] // 2 - 1)
    x = F.conv2d(x, filters, stride=2, groups=c, padding=pad)
    x = x.reshape(b, c, 4, h // 2, w // 2)
    return x


def inverse_2d_wavelet_transform(x, filters):
    b, c, _, h_half, w_half = x.shape
    pad = (filters.shape[2] // 2 - 1, filters.shape[3] // 2 - 1)
    x = x.reshape(b, c * 4, h_half, w_half)
    x = F.conv_transpose2d(x, filters, stride=2, groups=c, padding=pad)
    return x

# =========================================================
# WTConv2d åŠå…¶ä¾èµ–(_ScaleModule)
# ä» wtconv2d.py å¹¶å…¥ï¼Œå¹¶æ”¹ç”¨ conv.autopad + æœ¬æ–‡ä»¶çš„å°æ³¢å‡½æ•°
# =========================================================

class _ScaleModule(nn.Module):
    """
    ç®€å•åŒå‚æ•°ç¼©æ”¾æ¨¡å—ï¼šé€å…ƒç´ ä¹˜ä»¥å¯å­¦ä¹ æƒé‡ã€‚
    ä¸åŸ wtconv2d.py çš„å®ç°ç­‰ä»·ï¼ˆä¿ç•™å‚æ•°åä¸å½¢çŠ¶ï¼‰ï¼Œç”¨äºç¨³å®šè®­ç»ƒä¸­ä¸åŒåˆ†æ”¯çš„å¹…åº¦ã€‚
    """
    def __init__(self, dims, init_scale=1.0, init_bias=0):
        super().__init__()
        self.dims = dims
        self.weight = nn.Parameter(torch.ones(*dims) * init_scale)
        self.bias = None  # ä¸åŸå®ç°ä¿æŒä¸€è‡´ï¼ˆæœªä½¿ç”¨ biasï¼‰

    def forward(self, x):
        return torch.mul(self.weight, x)


class WTConv2d(nn.Module):
    """
    Wavelet-Enhanced DWConvï¼ˆäºŒç»´å°æ³¢ï¼‰
    - ç©ºé—´åˆ†æ”¯ï¼šé€é€šé“æ·±åº¦å¯åˆ†ç¦»å·ç§¯ + å­¦ä¹ å°ºåº¦
    - é¢‘åŸŸåˆ†æ”¯ï¼šå¤šå±‚ 2D DWT â†’ DWConvï¼ˆåœ¨å››ä¸ªå­å¸¦ä¸Šé€é€šé“ï¼‰â†’ å­¦ä¹ å°ºåº¦ â†’ é€å±‚ IWT é‡å»º
    - èåˆï¼šç©ºé—´åˆ†æ”¯è¾“å‡º + é¢‘åŸŸé‡å»ºç‰¹å¾
    - ä¸‹é‡‡æ ·ï¼šè‹¥ stride>1ï¼Œä½¿ç”¨ AvgPool2d(kernel_size=1, stride=stride) è¿›è¡Œæ­¥é‡‡æ ·ï¼ˆä¿æŒåŸè¡Œä¸ºï¼‰

    Args:
        in_channels (int): è¾“å…¥é€šé“
        out_channels (int): è¾“å‡ºé€šé“ï¼ˆéœ€ä¸è¾“å…¥é€šé“ä¸€è‡´ï¼Œç”¨äºé€é€šé“æ“ä½œï¼‰
        kernel_size (int): DWConv çš„æ ¸å¤§å°
        stride (int): ä¸‹é‡‡æ ·æ­¥å¹…ï¼ˆ>1 æ—¶åœ¨èåˆååšå¹³å‡æ­¥é‡‡æ ·ï¼‰
        bias (bool): ç©ºé—´åˆ†æ”¯ DWConv æ˜¯å¦å¸¦åç½®
        wt_levels (int): å°æ³¢åˆ†è§£å±‚æ•°
        wt_type (str): å°æ³¢ç±»å‹ï¼ˆå¦‚ 'db1'ï¼‰

    å…¼å®¹æ€§æ”¹å˜ï¼š
        - åŸå®ç°ä½¿ç”¨ padding="same"ï¼Œæ­¤å¤„ç»Ÿä¸€æ”¹ä¸º autopad(...)ï¼Œé¿å…å¯¹ PyTorch ç‰ˆæœ¬çš„ä¾èµ–ã€‚
    """
    def __init__(self,
                 in_channels: int,
                 out_channels: int,
                 kernel_size: int = 5,
                 stride: int = 1,
                 bias: bool = True,
                 wt_levels: int = 1,
                 wt_type: str = "db1"):
        super().__init__()

        assert in_channels == out_channels, "WTConv2d éœ€è¦ in_channels == out_channelsï¼ˆé€é€šé“å¤„ç†ï¼‰"

        self.in_channels = in_channels
        self.wt_levels = wt_levels
        self.stride = stride
        self.dilation = 1

        # 2D å°æ³¢æ»¤æ³¢å™¨ï¼ˆå†»ç»“å‚æ•°ï¼Œä¿ç•™åˆ° state_dictï¼‰
        wt_filter, iwt_filter = create_2d_wavelet_filter(wt_type, in_channels, in_channels, type=torch.float)
        self.wt_filter = nn.Parameter(wt_filter, requires_grad=False)
        self.iwt_filter = nn.Parameter(iwt_filter, requires_grad=False)

        # ç©ºé—´åˆ†æ”¯ï¼šé€é€šé“ DWConvï¼ˆç­‰ä»·äº groups=in_channels çš„ Conv2dï¼‰
        self.base_conv = nn.Conv2d(
            in_channels, in_channels,
            kernel_size=kernel_size,
            stride=1,
            padding=autopad(kernel_size, p=None, d=1),  # æ›¿ä»£ padding="same"
            dilation=1,
            groups=in_channels,
            bias=bias
        )
        self.base_scale = _ScaleModule([1, in_channels, 1, 1])

        # é¢‘åŸŸåˆ†æ”¯ï¼šæ¯å±‚å¯¹ 4 ä¸ªå­å¸¦åšé€é€šé“ DWConvï¼ˆgroups=in_channels*4ï¼‰
        self.wavelet_convs = nn.ModuleList([
            nn.Conv2d(
                in_channels * 4, in_channels * 4,
                kernel_size=kernel_size,
                stride=1,
                padding=autopad(kernel_size, p=None, d=1),  # æ›¿ä»£ padding="same"
                dilation=1,
                groups=in_channels * 4,
                bias=False
            ) for _ in range(self.wt_levels)
        ])
        self.wavelet_scale = nn.ModuleList([
            _ScaleModule([1, in_channels * 4, 1, 1], init_scale=0.1)
            for _ in range(self.wt_levels)
        ])

        # ä¸‹é‡‡æ ·ï¼ˆä¿æŒåŸå®ç°çš„â€œæ­¥é‡‡æ ·â€è¯­ä¹‰ï¼›å¦‚éœ€çœŸæ­£å‡å€¼ä¸‹é‡‡æ ·ï¼Œå¯æ”¹ kernel_size=strideï¼‰
        self.do_stride = nn.AvgPool2d(kernel_size=1, stride=stride) if stride > 1 else None

    def forward(self, x: torch.Tensor) -> torch.Tensor:
        # é€å±‚ DWT çš„ç¼“å­˜
        x_ll_in_levels = []  # æ¯å±‚çš„ LL å­å¸¦ï¼ˆç»å·ç§¯+ç¼©æ”¾åçš„ï¼‰
        x_h_in_levels = []   # æ¯å±‚çš„ LH/HL/HH å­å¸¦ï¼ˆç»å·ç§¯+ç¼©æ”¾åçš„ï¼‰
        shapes_in_levels = []

        # è‡ªé¡¶å‘ä¸‹åˆ†è§£
        curr_x_ll = x
        for i in range(self.wt_levels):
            curr_shape = curr_x_ll.shape  # [B,C,H,W]
            shapes_in_levels.append(curr_shape)

            # H/W ä¸ºå¥‡æ•°æ—¶è¡¥é½åˆ°å¶æ•°ï¼Œé¿å…ä¸‹é‡‡æ ·ç»´åº¦ä¸¢å¤±
            if (curr_shape[2] % 2 > 0) or (curr_shape[3] % 2 > 0):
                curr_pads = (0, curr_shape[3] % 2, 0, curr_shape[2] % 2)  # (left,right,top,bottom)
                curr_x_ll = F.pad(curr_x_ll, curr_pads)

            # DWT: [B,C,4,H/2,W/2]
            curr_x = wavelet_2d_transform(curr_x_ll, self.wt_filter)

            # LL å­å¸¦ä½œä¸ºä¸‹ä¸€å±‚è¾“å…¥
            curr_x_ll = curr_x[:, :, 0, :, :]

            # æŠŠ (C,4,H/2,W/2) è§†ä½œ (C*4, H/2, W/2) åšé€é€šé“ DWConv
            b, c, four, hh, ww = curr_x.shape
            curr_x_tag = curr_x.reshape(b, c * 4, hh, ww)
            curr_x_tag = self.wavelet_scale[i](self.wavelet_convs[i](curr_x_tag))
            curr_x_tag = curr_x_tag.reshape(b, c, 4, hh, ww)

            x_ll_in_levels.append(curr_x_tag[:, :, 0, :, :])      # LL
            x_h_in_levels.append(curr_x_tag[:, :, 1:4, :, :])     # LH/HL/HH

        # è‡ªåº•å‘ä¸Šé‡å»ºï¼ˆé€å±‚ IWTï¼‰
        next_x_ll = 0
        for i in range(self.wt_levels - 1, -1, -1):
            curr_x_ll = x_ll_in_levels.pop()
            curr_x_h  = x_h_in_levels.pop()        # [B,C,3,hh,ww]
            curr_shape = shapes_in_levels.pop()    # è®°å½•çš„åŸå½¢çŠ¶

            curr_x_ll = curr_x_ll + next_x_ll      # è‡ªåº•å‘ä¸Šçš„æ®‹å·®ä¼ é€’
            curr_x = torch.cat([curr_x_ll.unsqueeze(2), curr_x_h], dim=2)  # [B,C,4,hh,ww]
            next_x_ll = inverse_2d_wavelet_transform(curr_x, self.iwt_filter)

            # å»æ‰ä¸Šé¢ä¸ºå‡‘å¶æ•°åŠ çš„ pad
            next_x_ll = next_x_ll[:, :, :curr_shape[2], :curr_shape[3]]

        # é¢‘åŸŸåˆ†æ”¯é‡å»ºç»“æœ
        x_tag = next_x_ll

        # ç©ºé—´åˆ†æ”¯
        x_spatial = self.base_scale(self.base_conv(x))

        # èåˆ
        y = x_spatial + x_tag

        # ä¸‹é‡‡æ ·ï¼ˆæŒ‰åŸå®ç°æ­¥é‡‡æ ·è¯­ä¹‰ï¼‰
        if self.do_stride is not None:
            y = self.do_stride(y)

        return y
